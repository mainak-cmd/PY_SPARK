{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Collecting pyspark\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.0.1; however, version 21.2.3 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading pyspark-3.1.2.tar.gz (212.4 MB)\n",
      "Collecting py4j==0.10.9\n",
      "  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n",
      "Using legacy 'setup.py install' for pyspark, since package 'wheel' is not installed.\n",
      "Installing collected packages: py4j, pyspark\n",
      "    Running setup.py install for pyspark: started\n",
      "    Running setup.py install for pyspark: still running...\n",
      "    Running setup.py install for pyspark: still running...\n",
      "    Running setup.py install for pyspark: finished with status 'done'\n",
      "Successfully installed py4j-0.10.9 pyspark-3.1.2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Assingment1 \\\\\n",
    "a) Create RDD from CSV data below\n",
    "b) Create DF without giving schema and indicating it has header row \n",
    "c) Create DF by providing schema and indicating it has header row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType,DateType,DoubleType\n",
    "from pyspark import SparkContext, SparkConf\n",
    "spark=SparkSession.builder.appName('NEW').getOrCreate()\n",
    "sc = SparkContext.getOrCreate(SparkConf())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Create RDD from CSV data below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "distFile = sc.textFile(\"new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_new=distFile.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id;name;dob;salary;designation;managerid;address;hobbies',\n",
       " '1;Sachin;10/01/75;10000;Manager;2;{\"city\" : \"Bangalore\", \"state\" : \"Karnataka\"};\"cricket\",\"netflix\",\"walking\"',\n",
       " '1;Sachin;10/01/75;10000;Volunteer;2;{\"city\" : \"Bangalore\", \"state\" : \"Karnataka\"};\"cricket\",\"netflix\",\"walking\"',\n",
       " '2;Dolly;11/02/76;20000;Director;3;{\"city\" : \"Bangalore\", \"state\" : \"Karnataka\"};�walking�,�jogging�',\n",
       " '3;Rajesh;12/03/77;30000;VP;4;{\"city\" : \"Chennai\", \"state\" : \"TN\"};�walking�,�cricket�',\n",
       " '4;Kishore;14/04/78;40000;SVP;5;{\"city\" : \"Pune\", \"state\" : \"MH\"};�walking�,\"football�',\n",
       " '5;Naveen;15/05/79;50000;CEO;6;{\"city\" : \"Delhi\", \"state\" : \"Delhi\"};�music�,�netflix�',\n",
       " '6;Babu;16/06/80;60000;Chairman;0;{\"city\" : \"Jaipur\", \"state\" : \"RJ\"};']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Create DF without giving schema and indicating it has header row "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = spark.read.options(header='True',inferSchema='True',delimiter=';') \\\n",
    "  .csv(\"new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: int, name: string, dob: string, salary: int, designation: string, managerid: int, address: string, hobbies: string]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------+------+-----------+---------+--------------------+--------------------+\n",
      "| id|   name|     dob|salary|designation|managerid|             address|             hobbies|\n",
      "+---+-------+--------+------+-----------+---------+--------------------+--------------------+\n",
      "|  1| Sachin|10/01/75| 10000|    Manager|        2|{\"city\" : \"Bangal...|\"cricket\",\"netfli...|\n",
      "|  1| Sachin|10/01/75| 10000|  Volunteer|        2|{\"city\" : \"Bangal...|\"cricket\",\"netfli...|\n",
      "|  2|  Dolly|11/02/76| 20000|   Director|        3|{\"city\" : \"Bangal...| �walking�,�jogging�|\n",
      "|  3| Rajesh|12/03/77| 30000|         VP|        4|{\"city\" : \"Chenna...| �walking�,�cricket�|\n",
      "|  4|Kishore|14/04/78| 40000|        SVP|        5|{\"city\" : \"Pune\",...|�walking�,\"football�|\n",
      "|  5| Naveen|15/05/79| 50000|        CEO|        6|{\"city\" : \"Delhi\"...|   �music�,�netflix�|\n",
      "|  6|   Babu|16/06/80| 60000|   Chairman|        0|{\"city\" : \"Jaipur...|                null|\n",
      "+---+-------+--------+------+-----------+---------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- dob: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      " |-- designation: string (nullable = true)\n",
      " |-- managerid: integer (nullable = true)\n",
      " |-- address: string (nullable = true)\n",
      " |-- hobbies: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Create DF by providing schema and indicating it has header row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema1 = StructType([\n",
    "    StructField(\"id\", IntegerType()),\n",
    "    StructField(\"name\", StringType()),\n",
    "    StructField(\"dob\", DateType()),\n",
    "    StructField(\"salary\", DoubleType()),\n",
    "    StructField(\"designation\", StringType()),\n",
    "    StructField(\"managerid\", IntegerType()),\n",
    "    StructField(\"address\", StringType()),\n",
    "    StructField(\"hobbies\", StringType())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = spark.read.options(header='True',inferSchema='True',delimiter=';',schema=schema1) \\\n",
    "  .csv(\"new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------+------+-----------+---------+--------------------+--------------------+\n",
      "| id|   name|     dob|salary|designation|managerid|             address|             hobbies|\n",
      "+---+-------+--------+------+-----------+---------+--------------------+--------------------+\n",
      "|  1| Sachin|10/01/75| 10000|    Manager|        2|{\"city\" : \"Bangal...|\"cricket\",\"netfli...|\n",
      "|  1| Sachin|10/01/75| 10000|  Volunteer|        2|{\"city\" : \"Bangal...|\"cricket\",\"netfli...|\n",
      "|  2|  Dolly|11/02/76| 20000|   Director|        3|{\"city\" : \"Bangal...| �walking�,�jogging�|\n",
      "|  3| Rajesh|12/03/77| 30000|         VP|        4|{\"city\" : \"Chenna...| �walking�,�cricket�|\n",
      "|  4|Kishore|14/04/78| 40000|        SVP|        5|{\"city\" : \"Pune\",...|�walking�,\"football�|\n",
      "|  5| Naveen|15/05/79| 50000|        CEO|        6|{\"city\" : \"Delhi\"...|   �music�,�netflix�|\n",
      "|  6|   Babu|16/06/80| 60000|   Chairman|        0|{\"city\" : \"Jaipur...|                null|\n",
      "+---+-------+--------+------+-----------+---------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Create a case class Employee and then create a Dataset of type employee with below data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_employee=df4.select(['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|  name|\n",
      "+------+\n",
      "|Sachin|\n",
      "|Sachin|\n",
      "+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_employee.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Read empty table create below into a DF and show  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_empty = spark.createDataFrame([], StructType([]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python38264bit3cc16507011a48e5ad6af447e61a847b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
